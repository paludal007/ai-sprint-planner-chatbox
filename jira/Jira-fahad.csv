Summary,Description
Align Business Display Names Across Tools for Consistency,"There’s a UX inconsistency between tools when displaying businesses:

* The *Dev Portal* shows businesses by *Business ID*
* *Hub* and *StoreOps* show businesses by *Business Name*

This makes it harder to track or confirm which business you're working in across tools—especially when IDs and names don’t clearly align. I recommend updating the Dev Portal to match the Business Name format used elsewhere in the platform, or at minimum showing both Business Name and Business ID to reduce confusion

!Screenshot 2025-07-24 093500.png|width=570,height=500,alt=""Screenshot 2025-07-24 093500.png""!"
List Deliveries API Doesn't Show Orders Created in Portal,"Business: Nick Demo Account

I created 3 orders in the portal and 1 via API. All 4 show up in the portal. When I use the List Deliveries API, it only pulls the 1 order that was created by API and not the 3 manually created in the portal"
Undocumented 422 Error and Inconsistent Field Validation for Check Coverage Eligibility,"When simulating errors for the [*Check Coverage Eligibility*|https://developer.lynkup.com/tag/Delivery-Coverage?tag=Shipping-Management#operation/checkCoverage] API using the {{provider-coverage}} service, I intentionally omitted the required field {{locationExternalId}} to test error handling.

Instead of receiving a standard {{400 Bad Request}}, I received a *422 Unprocessable Entity* with the following payload:

{noformat}{
  ""type"": ""VALIDATION_ERROR"",
  ""errors"": [
    {
      ""type"": ""INVALID_DATA"",
      ""message"": ""locationExternalId or pickupAddress is missing for 'provider' service"",
      ""parameter"": null,
      ""entity"": null,
      ""entityId"": null
    }
  ],
  ""message"": ""Failed to process request""
}
{noformat}

A few issues here:

# *Undocumented 422 Error*: The API spec only lists {{400}}, {{401}}, and {{500}} responses. A {{422}} response is not documented
# *Confusing Validation Message*: The error mentions {{pickupAddress}} as an alternative to {{locationExternalId}}, but {{pickupAddress}} is *not documented* as a valid request field.
# *Contradictory Behavior*: If you attempt to include {{pickupAddress}} in the request body, you receive a {{400 Bad Request}} stating {{""pickupAddress is not allowed""}}.

*Expected Behavior*:

* The API should return a consistent {{400 Bad Request}} when required fields are missing.
* If {{pickupAddress}} is not supported, it should not appear in error messaging.
* API documentation should be updated to reflect correct required fields and all possible response codes, including {{422}} if it is intentionally used.
!2025-07-17_14-37-22.PNG|width=576,height=717,alt=""2025-07-17_14-37-22.PNG""!
!2025-07-17_14-32-43.PNG|width=1132,height=671,alt=""2025-07-17_14-32-43.PNG""!"
ClientId being mapped incorrectly when creating an app in LU,"*Environment*: Lynkup Prod
*Business*: Implementation Team Testing

Details from [~accountid:6355a870b7b39379d71f015e] post.

I'm running into an odd issue trying to test APIs - it almost seems like the credentials are pointing to a different business than the Application is created on. This is happening on 2 different businesses with 2 unique email addresses 
Business: Implementation Team Testing
User: Nick Davies ([nickdaviesfc@gmail.com|mailto:nickdaviesfc@gmail.com])
Applications: Nick Implementation Team & NickImplementation2Examples of issue:

* I make a List Locations call, which provides a 200 response, but the response is blank
* Get Location call for a specific location (Brawndo002) says the Location ID is not found even though it's on the account
* Create Location call fails because it says Brand ID (Brawndo) does not exist even though it's on the account
* There are other examples as well but they all fall along these lines

I can use the Client ID and Secret from Charles or Michael's applications on the same account and they work just fineThis issue is also happening on Nick Demo Account, which has a different user (Nick Developer) and different email address ([nick_davies@outlook.com|mailto:nick_davies@outlook.com])I've worked with [@Charles Does|https://delivery-solutions.slack.com/team/U04L1ANCLJX] and [@Michael Elliott|https://delivery-solutions.slack.com/team/U03PWAQ76Q4] and they are seeing the same issue as me when using the credentials from my application. 

+*Mohamed Fahad*+ looked at this and understands the mapping issue.

Slack Chat:
[https://delivery-solutions.slack.com/archives/C07GUMC9A02/p1752688736321779|https://delivery-solutions.slack.com/archives/C07GUMC9A02/p1752688736321779|smart-link] 

Cc: [~accountid:632d5c92b2e3c5ad0fa30eb8] [~accountid:6355a870b7b39379d71f015e] "
"Rate API request fails due to deliveryAddress.street1 marked as required, but documentation only requires postalCode.","While testing the *Rate API*, a validation error is returned stating:

{noformat}{
  ""type"": ""INVALID_DATA"",
  ""message"": ""deliveryAddress.street1 is a required field. The field is missing."",
  ""parameter"": ""deliveryAddress.street1""
}
{noformat}

However, according to the documentation, the *only required field* within {{deliveryAddress}} is {{postalCode}}, and there is no mention of {{street1}} being mandatory for rate lookup.

*Relevant section from documentation:*

{quote}""The minimum required parameters for the Rate API are {{postalCode}} in the {{deliveryAddress}} and the {{locationExternalIds}}.""{quote}

This discrepancy suggests the backend schema or validator may be overly strict or misaligned with the documented requirements. 



This call does work when including a full address as mentioned, but not with min requirements"
orderStatus.updatedAt in Get Delivery Status rs not in ISO 8601 format,"The {{orderStatus}} object within Get Delivery Status RS is {{a}}a human-readable string (""July 11th 2025, 12:12:07 pm CDT"")

This is *not compliant* with the documented schema, which advised a standard ISO 8601 datetime string (e.g., {{""2025-07-11T12:12:07-05:00""}}).

This inconsistency could cause schema validation failures or parsing issues for consumers expecting machine-readable timestamps.

*Impacted field:*

* {{orderStatus[].updatedAt}}

*Expected format (per schema):*

* ISO 8601: {{YYYY-MM-DDTHH:MM:SSZ}} or with offset"
Edit Location response missing id and createdAt fields,"Per the Edit Location Response schema documented on [developer.lynkup.com|https://developer.lynkup.com], a successful Edit Location response should include both {{id}} (string, ≤100 characters) and {{createdAt}} (string). However, when editing location {{152946}} under ""Implementation Team Testing,"" the successful  response did not contain either of these fields.

!2025-07-07_11-36-29.PNG|width=688,height=522,alt=""2025-07-07_11-36-29.PNG""!

Request and response example attached for reference."
"Delivery response is missing required timestamp fields (createdAt, lastUpdatedAt)","This is occurring on the RSs for Create Delivery, List Deliveries, Get Delivery, Cancel Delivery, Edit Delivery. 

When performing API testing on the delivery endpoint, the response payload includes {{createdDate}} but sets its value to {{null}}. Additionally, both {{createdAt}} and {{lastUpdatedAt}} are completely missing from the response.

According to the API documentation:

* {{createdAt}} and {{lastUpdatedAt}} are *required fields* and should be returned in ISO 8601 format.
* {{createdDate}} is optional but usually contains a Unix timestamp.

This discrepancy could affect consumers relying on delivery record creation times for tracking, auditing, or downstream workflows. It also represents a schema validation failure against the published docs. Screenshot and full rs attached from test order 77055 under implementation_team_testing. "
Lynkup no longer supports the Delete Multiple Boundaries API — only single-boundary deletion remains available.,"*The Delete Multiple Boundaries API is no longer available in LynkUp — only the single Delete Boundary endpoint remains.*

Previously, the DS APIs supported both single and bulk boundary deletions—allowing you to delete a specific boundary using the {{Delete Boundary}} API or remove multiple boundaries tied to a pickup location using the {{Delete Boundaries}} API.  [Delete Boundaries|https://docs.deliverysolutions.co/reference/delete-boundaries] 

In the new LynkUp API documentation, only the single {{Delete Boundary}} API is referenced. This version requires a boundary ID passed as a path parameter, meaning customers must delete boundaries one at a time rather than in bulk.

It’s unclear how widely the bulk deletion option is currently used, but if the intention is to deprecate support for removing multiple boundaries via API, I’ll need to confirm that to provide accurate guidance."
notifySms and notifyEmail removed from DeliveryContact object in LU,"Per our [Lynkup API Change Log|https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/1138884670/Change+Log], notifySms and notifyEmail have been removed from DeliveryContact object in LU delivery payload.

These objects are important for customer opt in/opt out requirements. 

They need to be passed _per order_, especially the notifySms flag as: 

* Our clients can get into trouble for texting customers that have not _explicitly_ opted in and lose the ability to send SMS messages through Twilio (our SMS partner service).
* This flag prevents us from sending a text message to customers if it is set to false, even if that order falls in a flow that would get a text message (“Your order is out for delivery” etc)





These should be added back in, and testing should confirm that if notifySms is set to False that NO SMS messages are sent in regards to that order."
"API Documentation Rename ""Locations"" to ""Create Boundary""","On [API Documentation - LynkUp|https://developer.lynkup.com/tag/Locations?tag=Shipping-Management#operation/getListOfBoundaries], the “Create Boundary” API has been renamed “Locations”. Please change back as the new name does not reflect the tool and will be confused with location apis "
Cross track PR review for DL 54959,
Cross Track Review,"PR review Needed for the ticket [https://delivery-solutions.atlassian.net/browse/DL-55414|https://delivery-solutions.atlassian.net/browse/DL-55414|smart-link] 

PRs need approval 

# [https://bitbucket.org/deliverysolutions/api.deliverysolutions/pull-requests/18558|https://bitbucket.org/deliverysolutions/api.deliverysolutions/pull-requests/18558|smart-link] 
# [https://bitbucket.org/deliverysolutions/providers-service/pull-requests/719/overview|https://bitbucket.org/deliverysolutions/providers-service/pull-requests/719/overview|smart-link] "
Production Traffic Audit Q1 2025,
Update FedEx trackingUrl in providerMaster,"Update FedEx trackingUrl from 

{noformat}https://www.fedex.com/fedextrack/?{noformat}

to

{noformat}https://www.fedex.com/fedextrack/?action=track&trackingnumber={noformat}

in Fedex ShipEngine in providerMaster collection."
Update FedEx trackingUrl in providerMaster,"Updated FedEx trackingUrl from 

{noformat}https://www.fedex.com/fedextrack/?action=track&trackingnumber={noformat}

to 

{noformat}https://www.fedex.com/fedextrack/?{noformat}

in FedEx Native as well as Fedex ShipEngine providers in providerMaster and provider collection."
Onfleet PO requests are missing the Team Id within container object field,"+*This is an escalation from L2 to L3*+

Onfleet PO requests are missing Team Id in container object.

Save on Foods and Onfleet submitted a support ticket today questioning why orders were not being assigned in Onfleet's system. The SOF Onfleet configuration hasn't changed recently. Onfleet's team is manually having to assign the affected orders on their end.

missing field:

!image-20250131-044811.png|width=750,height=242,alt=""image-20250131-044811.png""!

expected container object with team field:

!image-20250131-044839.png|width=712,height=216,alt=""image-20250131-044839.png""!

examples (partial list from ZD):

Jan 30:
42086832 - 977
42086765 - 993
42086801 - 957
42086842 - 951
42086787 - 932
42086818 - 967
42086880 - 928
42086848 - 980


example log: [https://onenr.io/02R527onPjb|https://onenr.io/02R527onPjb] (42086832)

This appears to be related to sunsetting Store Hierarchy and using Driver Service to obtain the Team ID that went live in the latest prod release (S110) - R2025-105.0.0

ref: [https://delivery-solutions.atlassian.net/browse/DL-47535|https://delivery-solutions.atlassian.net/browse/DL-47535]

Upon investigating a list of affected orders sent by SOF, we can see that the request to Onfleet is missing the Team ID within the container object. 

This is has occurred intermittently and without any errors in the logs.



* Please see Zendesk Support tab for further comments and attachments."
Review repository changes for scheduled pickups changes,
Scheduled pickups API changes review - UPS Governance,
Review Edit Tracker Open API Specs,
Review Rates Response in OpenAPI Specs,
Review Create Tracker OpenAPI Specs,
Cross Track Review:DL-34767,
Cross Track Review: Repository Changes for Cross Border Shipping,
Google Geocoding Optimisation,"google says its rare but it happens and mentions a way to solve it optimally: [https://developers.google.com/maps/documentation/datasets/web-service-best-practices#exponential-backoff|https://developers.google.com/maps/documentation/datasets/web-service-best-practices#exponential-backoff]

_Issue created in Slack from a_ [_message_|https://delivery-solutions.slack.com/archives/C0127ND265A/p1731614648883069?thread_ts=1731612731.010369&cid=C0127ND265A]_._"
Perf test to check if we are meeting client SLAs,
Repository PR review for custom rates changes,
Add Meijer to FedEx polling lambda,"Escalating to L3 to add Meijer to the FedEx polling lambda

~* Please see Zendesk Support tab for further comments and attachments.~"
SDD API hits,"We got to know we are hitting SDD rate limits due to which few orders are getting failed so we need some statistic data to analyse regarding number of hits happening to Same day delivery.

Need is asap as we might have to fix it before freeze period to avoid unwanted order failures in Holiday season"
Performance Load Testing,"Tenant: Michaels
Env: Sandbox

Michaels is requesting a load test for 9/30 


* Please see Zendesk Support tab for further comments and attachments."
PR review for repository changes related to shipping rates,
PR Review,"DEv Pr: [https://bitbucket.org/deliverysolutions/providers-service/pull-requests/267/diff|https://bitbucket.org/deliverysolutions/providers-service/pull-requests/267/diff|smart-link] 
QA Pr: [https://bitbucket.org/deliverysolutions/providers-service/pull-requests/276|https://bitbucket.org/deliverysolutions/providers-service/pull-requests/276|smart-link] 

Sandbox: [https://bitbucket.org/deliverysolutions/providers-service/pull-requests/314|https://bitbucket.org/deliverysolutions/providers-service/pull-requests/314|smart-link] 


Repository Changes : 
Beta Pr: [https://bitbucket.org/deliverysolutions/repository/pull-requests/864|https://bitbucket.org/deliverysolutions/repository/pull-requests/864|smart-link] 

RC: [https://bitbucket.org/deliverysolutions/repository/pull-requests/913/overview|https://bitbucket.org/deliverysolutions/repository/pull-requests/913/overview|smart-link] "
Verification of Stuck Consumption Problem,
Enable returns summary page on production,"[https://delivery-solutions.atlassian.net/browse/DL-44997|https://delivery-solutions.atlassian.net/browse/DL-44997|smart-link] 

Once the above bug is fixed we need to enable the returns summary page"
Load Test For Wakefern PO Curbside,"Background: 
Need to do a load test(Perf ENV) based on Wakefern store 606 and its related orchestration rule as we observed missing fetch logs in orders at random. Need to know the frequency of the issue and the approximate percentage of replication.

The load limit needs to match the wakefern production load on Perf Env.

This is required to complete the RCA for missing fetch logs

Order Link: https://production.portal.deliverysolutions.co/#/deliveries/status/orders/order_details/66d034cb17ece65a9e1e3a62 

Tenant: Wakefern V8

NewRelic Log Link: https://onenr.io/0vwB8n4M8jp

~* Please see Zendesk Support tab for further comments and attachments.~"
Review Repository library changes for Return webhook logs (DL-38905),
Performance Testing for Hosted Returns Page,Performance Testing for Hosted Returns Page
Sephora Smart Windows has elevated response times,"_This is an escalation from L2 to L3._

Sephora has raised a concern that Smart Windows calls have been taking longer than usual and are timing out on their end. Upon investigating duration metrics via New Relic we have observed that  the P95 duration has increased to above .3 seconds (which is their threshold) beginning just after 11 pm CST on 6/18, which coincides with the OR Prod Special Release (R2024-76.1.0). 

!image-20240626-231427.png|width=91.66666666666667%,alt=""image-20240626-231427.png""!



* Please see Zendesk Support tab for further comments and attachments."
Analyse whether API Cron is able to handle 5x Webhook Traffic,"On 30th of May we received a surge in traffic of webhooks from Uber, it was 4x of normal load. Our system ideally should be able to withstand such traffic. Need to analyse why our system started returning 5xx error during this spike.

[https://radar-api.service.newrelic.com/accounts/2626587/issues/711d52d3-192b-4d2b-92fe-ee55a574ad09?notifier=SLACK_LEGACY|https://radar-api.service.newrelic.com/accounts/2626587/issues/711d52d3-192b-4d2b-92fe-ee55a574ad09?notifier=SLACK_LEGACY]

!image-20240604-083108.png|width=1565,height=468,alt=""image-20240604-083108.png""!



!image-20240604-083115.png|width=1536,height=865,alt=""image-20240604-083115.png""!"
Point Atlas Triggers to the new Order Collection ,"[https://cloud.mongodb.com/v2/5a8459294e65811a12cfa4c7#/triggers/64de30d2e0b5c4bc8c813b3a|https://cloud.mongodb.com/v2/5a8459294e65811a12cfa4c7#/triggers/64de30d2e0b5c4bc8c813b3a]
[https://cloud.mongodb.com/v2/5a8459294e65811a12cfa4c7#/triggers/64156a229aba0ba532ce115b|https://cloud.mongodb.com/v2/5a8459294e65811a12cfa4c7#/triggers/64156a229aba0ba532ce115b]

These are the two triggers that we will need to change post our release."
Remove refId and sortId from API Docs,Remove refId and sortId from API Docs
Review The Repository Code For Labels V3,[https://bitbucket.org/deliverysolutions/repository/pull-requests/473|https://bitbucket.org/deliverysolutions/repository/pull-requests/473|smart-link] 
Code Review of DL-8857 by Delivery Management,Code Review of DL-8857 by Delivery Management
Clean up Labels Model in Readme.io,"Clean up Labels Model in [http://Readme.io|http://Readme.io|smart-link] 
[https://docs.deliverysolutions.co/reference/label|https://docs.deliverysolutions.co/reference/label|smart-link]
 "
Publish eventdbClient method in db collection library,Publish eventdbClient method in db collection library
Run migration on PROD to remove saveOrders endpoint from apiRoutes,
Code Review for DL-23918 - Fahad,[https://bitbucket.org/deliverysolutions/authorizer/pull-requests/290|https://bitbucket.org/deliverysolutions/authorizer/pull-requests/290|smart-link] 
Submit APIs to the UPS Governance team for review,"We have to submit our APIs to the UPS Governance. These APIs will be fronted by Apigee gateway. We need to correct the urls in [https://delivery-solutions.atlassian.net/browse/DL-5802|https://delivery-solutions.atlassian.net/browse/DL-5802|smart-link] and then modify make our APIs in line with the guidelines.

Once the effort is completed for the 70 Public APIs, we submit the same to the Governance team"
Update the client id and env variable,"As UPS has changed the mapping of lynkup gateways on their end, they are getting errors with the payload. They have mapped the LynkUp sys gateway to our qa api gateway. We have to change the env variable in authoriser / api to handle the changed authentication url. We should map one of the QA tenants with this clientId. 

{noformat}Hi Sukumar,

APIGEE Sys is pointing to DS ‘qa-apigee.api.deliverysolutions.co’ and we are getting 403 from DS. Can you whitelist IP on your end (please see email below from Sai).
We are working on creating pub/sub subscription in sys. We will share once we have details.
Thanks,

Madhuri{noformat}

{noformat}Hi Sukumar,
Can you please whitelist our sys clientId: AvGK5MT9m2fn6MxEHglFj2elar6gGd5GxfaeMxQqtalAnE0V
JWKS for sys: GET https://entapis-sys.ams1907.com/ent-services/security/v1/jwks

Thanks,

Madhuri{noformat}

# Look at [https://delivery-solutions.atlassian.net/browse/DL-40147|https://delivery-solutions.atlassian.net/browse/DL-40147|smart-link]  and add replace the lambda url with this JWKS sys url in the qa authoriser env
# Add this client id to an existing LynkUp tenant on QA env
# Sync with Madhuri in UPS to update the curls she uses for testing
# Update the pub sub env variables in API / Authoriser based on [https://delivery-solutions.atlassian.net/browse/DL-4276|https://delivery-solutions.atlassian.net/browse/DL-4276|smart-link] "
Environment Variable changes for Smart Scaling Lambda [API Rule] - Production,Environment Variable changes for Smart Scaling Lambda [API Rule] - Production
Environment Variable changes for Smart Scaling Lambda [API Rule] - Sandbox,Environment Variable changes for Smart Scaling Lambda [API Rule] - Sandbox
Environment Variable changes for Batching Processor - Production,Environment Variable changes for Batching Processor - Production
Environment Variable changes for Batching Processor - Sandbox,
Environment Variables for Place Order Async Consumer - Production,
Environment Variables for Place Order Async Consumer - Sandbox,
Create report for testing and cleanup improvements due to order entity standardization,"This table should tell the business value of the whole exercise

h3. Business Value: *Unit test cases*

||*Service*||*Previous*||*Current*||*% Improvements*||
|Status-Polling|0%|95.83%|95.83%|
|Smart-Windows|12.54%|13.49%|1%|
|Streaming-Service|24.3%|43.54%|20%|
|Communication Service|7.28%|7.64%|0.5%|
|Retry Service|35.35%|44.17%|9%|
|Business Rules|100%|100%|0%|
|API (No of Test Cases)|46|129|180%|

||*Business Value*||*Previous*||*Current*||*% Improvements*||
|APIs with unit test cases|~ 8|31|287.5%|
|Customer Place order scenarios|14|32|128%|
|Automated Test scenarios|10|55|450%|
|APIs with Automated Test Cases|~15|47|213%|
|API Contract Inconsistencies|56|-|-|
|Database Footprint|18kb - average document size|5kb - average document size|~300 GB reduction in order collection|
|Customer Scalability (reducing risk of dehandles) - Multitenant|~64k|~60k|6.5%|
|Queries optimized (indexes improved) - Multitenant|36 indexes|32 indexes|272 queries optimised|

||*Cleanup Activity*||*Previous Count*||*Current Count*||
|Entity Fields (deprecation) - Order Entity|3700+ garbage & unused fields|7|
|APIs (removal of dead APIs) - Order Resource|18|15|"
Update s3 bucket policy on Prod (both Oregon and N. Virginia),"The below policy needs to be added in S3 bucket permission for s3 putobject
 

{noformat}        {
            ""Sid"": ""3"",
            ""Effect"": ""Allow"",
            ""Principal"": {
                ""AWS"": ""<arn>""
            },
            ""Action"": ""s3:PutObject"",
            ""Resource"": [
                ""arn:aws:s3:::<bucket-name>/*.xlsx"",
                ""arn:aws:s3:::<bucket-name>/*.xls"",
                ""arn:aws:s3:::<bucket-name>/*.png"",
                ""arn:aws:s3:::<bucket-name>/*.jpg"",
                ""arn:aws:s3:::<bucket-name>/*.jpeg"",
                ""arn:aws:s3:::<bucket-name>/*.json"",
                ""arn:aws:s3:::<bucket-name>/*.ttf"",
                ""arn:aws:s3:::<bucket-name>/*.zip""
            ]
        }{noformat}"
Dashboard for performance tests trends visualisation,"Source: [~accountid:5fe04e4fb66825010e13c555] 

{quote}Can we have a dashboard created for all public-facing APIs (trend/line graph)…let me know if you’d like a call with Chinmay and me to discuss requirements further tom..intent is to show performance delta in a visualization format every time we do performance test…{quote}"
Rate Call Latency - Performance Team,"*Source*: [~accountid:5fe04e4fb66825010e13c555] 

*Background*: Assigning a task to the performance team - improving rate call response (<250ms), presently ~500ms, as a known issue.

Source of data - P95 column @ [https://delivery-solutions.atlassian.net/wiki/spaces/RD/pages/658407491/23rd+May+Production+R2023-32.0.0|https://delivery-solutions.atlassian.net/wiki/spaces/RD/pages/658407491/23rd+May+Production+R2023-32.0.0|smart-link]  



* Please see Zendesk Support tab for further comments and attachments."
Sign Off on Infra Changes as per Recommendations by Performance Team,Sign Off on Infra Changes as per Recommendations by Performance Team
Perform a load test to compare the speed of Write when using w:1 and when using w:majority,"As described in [https://delivery-solutions.atlassian.net/browse/DL-16758|https://delivery-solutions.atlassian.net/browse/DL-16758|smart-link]  we would like to compare the speed of writes when using {{w:1}} and when using {{w:majority}}

*  Run our usual write load test with {{w:majority}} and mark the matrices
* Run our usual write load test with {{w:1}} and mark the matrices
* Compare the Execution times

{panel:bgColor=#deebff}
use wtimeout: 500 for w:majority
{panel}"
Update cache-service version to 3.4.23 in sandbox and prod,
Evaluate amount of read latency from OHIO region with NV region,"In order to have full functional regional outage, we are adding one more region to the cluster group [OHIO].

This card is to determine the OHIO read latency and compare with  NV latency."
POC on AWS App Mesh for networking in ECS,"AWS App Mesh is a service mesh that can help you manage a large number of services and have better control of how traffic gets routed among services. App Mesh functions as an intermediary between basic service discovery and load balancing. With App Mesh, applications don't directly interact with each other, but they also don’t use a centralized load balancer either. Instead, each copy of your task is accompanied by an Envoy proxy sidecar. 

!https://docs.aws.amazon.com/images/AmazonECS/latest/bestpracticesguide/images/appmesh.png|alt=""
                    Diagram showing architecture of a network using a service mesh.
                ""!


We need to conduct a POC On APP mesh and see if using it can benefit us to route traffic for our internal services.

References:

[https://docs.aws.amazon.com/AmazonECS/latest/bestpracticesguide/networking-connecting-services.html|https://docs.aws.amazon.com/AmazonECS/latest/bestpracticesguide/networking-connecting-services.html|smart-link]
[https://docs.aws.amazon.com/app-mesh/latest/userguide/what-is-app-mesh.html|https://docs.aws.amazon.com/app-mesh/latest/userguide/what-is-app-mesh.html|smart-link]"
Explore Networking Fundamentals - Fahad,
Find cause of container restarts,"{quote}service [api-prod|https://us-west-2.console.aws.amazon.com/ecs/home?region=us-west-2#/clusters/api-prod/services/api-prod] (instance i-08a97c83dd255d187) (port 49159) is unhealthy in target-group [api-prod-tg|https://us-west-2.console.aws.amazon.com/ec2/v2/home?region=us-west-2#TargetGroups:search=arn:aws:elasticloadbalancing:us-west-2:375882193182:targetgroup/api-prod-tg/632c4691dffaacb5] due to (reason Request timed out){quote}



The request timeout event happens when the health check URL does not respond in the designated amount of time 2 times consequnt

Whenever this event happens, we get 5XX errors. Hence, we need to find what causes these issues. One way to identify, is to create a dashboard under All Prod Traffic in Production-api-performance dashboard to detect when these things happen for which MSes. Then, find if we can find common backend requests that can trigger this issue."
Do Performance Testing after adding the New Self healed Key in the filter function,
Setup data.json for Endurance Tests,Setup data.json for Endurance Tests
UPS Compliance Training - Optimisation - Fahad,
Endurance Test SOPs,
Notification service metrics for performance environment should be integrated on new relic,
Need a performance suite for testing Order Listing API for portal,Our portal consistently has many filters added/removed sometimes sort fields are also added. We need a suite that can do performance analysis of the portal order listing API that can help us do an evaluation of all the scenarios and see that we do not move away from our existing benchmarks.
Jenkins pipeline to clean up db data before load testing,The current Jenkins pipeline to clean up DB data is broken.  We need to fix the issue and bring it back online.
Link scale up and scale down strategy co-relation with EC2 & containers ,[https://docs.google.com/spreadsheets/d/1FKGhS_Q3rp6dcbPAWVhz1SOrLNgliQqfPCaGm1MVphY/edit?usp=sharing|https://docs.google.com/spreadsheets/d/1FKGhS_Q3rp6dcbPAWVhz1SOrLNgliQqfPCaGm1MVphY/edit?usp=sharing|smart-link]
Set up cron-perf service in performance environment,[https://us-west-2.console.aws.amazon.com/ecs/v2/clusters/cron-perf/services/cron-perf/deployments?region=us-west-2|https://us-west-2.console.aws.amazon.com/ecs/v2/clusters/cron-perf/services/cron-perf/deployments?region=us-west-2]
Review Performance Test Suit & do necessary modification,
Load test on sandbox for response time,"* Performance benchmarking for real-time predictions using ML model
** Keep the environment config the same as that used for DA performance benchmarking.
** Each request to the model should comprise a single query since each request to the DA-DPS call comprise a single query
** Setup model autoscaling as well if required.



After reviewing the initial performance reports, following tests needs to be performed

* Perform perfomance testing on individual models for 10K samples directly
* Based on the above results, increase the number of instances for the sagemaker model and again the above test
* Keeping the throughtput same as that of DA-DSP and then vary the number containers… at the sametime observe the error % rate reduction"
Performance Benchmarking for Client Facing APIS (For S2022-20.0.0 24-MAY Sandbox),
Portal Benchmarking (For S2022-20.0.0 24-MAY Sandbox),
Performance of all APIs (For S2022-20.0.0 24-MAY Sandbox),
 Test postmate for performance  and check if the right index is there of orderTenantMapping collection,
Perf test for DL-8285 Ability to Get a List of Orders via API,
Add store_external_id index to geofences,
Orchestration revamp performance check,"# Check whether the orchestration revamp is under 1 second for all operations 
Create rule
Edit rule
Assign store
Delete rule
Remove assignment
Update assignment

2. Check if the CPU consumed is within 40% for all of the above operations
3. If the SLAs are not being met, then check what is degrading it"
Portal Benchmarking (For 10-MAY Sandbox) [Deferred],
Performance of all APIs (For 10-MAY Sandbox),
Performance Benchmarking for Client Facing APIs (For 10-MAY Sandbox),
Portal Benchmarking (For 26-APR Sandbox),
Performance of all APIs (For 26-APR Sandbox),
Performance Benchmarking for Client Facing APIs (For 26-APR Sandbox),
Portal Benchmarking (For 5-APR Sandbox),
Performance of all APIs (For 5-APR Sandbox),
Performance Benchmarking for Client Facing APIs (For 5-APR Sandbox),
Change memory reservation of api-prod and api-dr container,
Performance Benchmarking for Client Facing APIs (For 3-MAR Sandbox),
Portal Benchmarking (For 3-MAR Sandbox),
Performance of all APIs (For 3-MAR Sandbox),
Performance Benchmarking for Client Facing APIs (For 15-FEB Sandbox),
Portal Benchmarking (For 15-FEB Sandbox),
Performance of all APIs (For 15-FEB Sandbox),
Identify Performance issue (For 1-FEB-Sandbox),
Designing Performance Environment Process,
Integration with New Relic,
Performance Benchmarking for client Facing APIs (For 1-FEB Sandbox),
Portal Benchmarking (For 1-FEB Sandbox),
Performance Test of all APIs (For 1-FEB Sandbox),
API Gateway Set up,
Database Schema Design For Performance Environment,
SmartWindows timeouts (experiencing intermittently by Sephora) ,
Evaluate issues with Sephora in their DA calls (experiencing intermittent timeouts),
Perform load testing for DA on Sandbox,
Performance benchmarking for Client Facing APIs (For 18-JAN Sandbox),
Endurance Test for Aug-2022,
Endurance Test - Sep-2022,
Portal Benchmarking (For 18-JAN Sandbox),
Performance of all APIs (For 18-JAN Sandbox),
Create Smart Windows performance test scenarios,"Smart Windows API is to be used on customers' website and hence it is important that P95 < 300ms and P99< 1s. 

Smartwindows has multiple scenarios based on

1. number of stores
2. capacity check
3. days checked
4. brand/business/ store level settings

Based on all permutations create performance suite to test smart windows"
Caching Document,"Source: Sharmil

Scope:
Need document on
* what has been covered till now, how to use
* if any future upgradation"
Impact of status watching features on database performance,"# The notification timer checks for orders in a particular status and then sends notifications
# Similarly, streaming also watches orders for a particular status
# User Notification also checks for orders in a particular status and then sends notifications on the portal
# Order can be canceled and cloned from ORDER_DISPATCHED status after X mins

Sally has several orders in dispatched status and hence can cause problems. Wakefern has also got SRV orders in dispatched status only.



Check if several portal users subscribe and open active orders and usernotifications on portal

Check if several alerts have to be sent due to notification timer. "
Create inventory of all inefficiently indexed queries,"Go through each MS and find all the find and aggregate queries. If the collection referenced has the potential to have more than 1000 records then find explain plan for all flavors of the query. Please create a large dataset for these collections to test the impact.

||*MS*||*Class  / Function Name*||*Query*||*Explain Plan for large data set*||*API needing the query*||*keysExamined/docsReturned without limit*||*Node used for query*||*Problematic issues*||
| | | | | | | | |
| | | | | | | | |



*List of Problematic Issues*

# Sort key not part of index (sort in memory)
# Coll scan 
# Lookups
# Large amount of $in *with sort* (if sort is not used then $in is fine)
# $nin , $ne , $exist
# $push
# ESR is being followed of not
# Inefficient aggregation pipeline
# Projections not being used



*API List of alive APIs (95%):*
Use the list made for Privileged Escalation

*Other features not in API List:*

* Notification
* Notification timer
* Crons
* MS-MS Api Calls
"
Rate API Performance Check,"Source: Ramakant
"
Ensure MySQL RDS Instances have Custom Parameter Groups Assigned,"*Background*
MySQL databases that were newly created to be within our VPC were created with default MySQL parameter groups. Parameter groups is a concept in AWS to allow parameters for a DB version to be assigned to the DB. To customise the values of the parameters, custom parameter groups need to be created and assigned. The assignment takes a DB restart. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithParamGroups.html

*Requirements*
* Create a custom group for each type of DB we support, across our environments.
* Assign the custom group to the database.
* Immediately or schedule the application of the custom group to take effect on the DB."
Store boundary api giving unexpected results when tenantId (in lower case) is sent in headers,"Store Boundary API ([https://$\{env}.api.deliverysolutions.co/store/boundary|https://$%7Benv%7D.api.deliverysolutions.co/store/boundary]) is not giving expected results when we send tenantId in lower case (tenantid) in our headers

*RCA:*

The above-mentioned API is authenticated by ApiKey authorizer which returns {{tenantId}} in response, the response is mapped to API gateway variable {{tenantId}}, express then transforms this to lowercase {{tenantid}} and if the user has explicitly sent {{tenantid}} in the API request, then there are two headers with the same name, which are concatenated as per the HTTP RFC 2616 specification.

Thus resulting concatenated value is invalid which causes our API to behave in an unexpected manner.

[https://stackoverflow.com/questions/36439308/parse-duplicate-http-headers-from-request-in-node|https://stackoverflow.com/questions/36439308/parse-duplicate-http-headers-from-request-in-node|smart-link]  "
Investigate Large Build Downloads on Page Open,"We have implemented lazy loading and hence, application is downloaded in pieces. But the pieces itself are quite large leading to slower page loads. Find out how we can optimize the build size. Rushabh can help you as he implemented it."
