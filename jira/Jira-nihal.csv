Summary,Description
Performance testing for workflow-builder Ms,"As part of Enhancement being done for [https://delivery-solutions.atlassian.net/browse/DL-61799|https://delivery-solutions.atlassian.net/browse/DL-61799|smart-link]  Bug

We have made few changes related to Cache implementation to reduce CPU utilization.



*Objective:* To compare the overall effectiveness of Fix of Workflow-builder. This will help to gauge the new changes.

Dev Url - [https://dev.workflows-builder.lynkup.com/|https://dev.workflows-builder.lynkup.com/] 

Will need Perf sign-off for those new changes.



Note: workflow-builder is already made to Prod as this was internal application and not public facing.

Reach out to [~accountid:5f4ddee0333edb00432ffff9] [~accountid:712020:a6a4bceb-f4b4-4b10-8df8-8be6179baa1e]  [~accountid:712020:b01040ae-15ec-4a86-adab-f392074fbc58] for any query."
Check Performance for Label V2,"we have used the Parameter store for using environment variables, so the sensitive information is not exposed, please check that it doesn't have impact on the latency of label V2"
Performance Test of Provider Webhooks with DR Region,Performance Test of Provider Webhooks with DR Region
Performance Testing for Event Entity Framework,"Performance Testing for Event Entity Framework

The event processor service is a new service hence we need to provide the CPU and Memory Requirements, Task Placements Strategy and Auto Scaling Policies."
Simulation cluster Performance Testing Required: Rate API in new Infra With Provider Service and min 1 instance of each API to reduce the cost,
Performance Test to evaluate plancache in MongoDB,
Performance recommendation for implementing the managed draining in capacity provider,"Currently, our older services do *not* have managed draining enabled in the capacity provider. This has led to EC2 instances being terminated immediately after tasks are stopped, sometimes while they're still carrying active tasks.

During the Ware2Go testing, we enabled *managed draining* and observed that EC2 termination was handled gracefully, in sync with ECS task lifecycle.

Please test this setup in your environment and share your recommendations on adopting managed draining for capacity providers."
Performance recommendation for Task deregistration delays in target groups.,"Currently the Task deregistration delays as 300 seconds in target groups, which is default value.
AWS team has recommended to have Task deregistration delays as 700 seconds in target groups. Please perform the test to check the impact of adding Task deregistration delays in all the ecs service configuration."
Performance recommendation for increased Scale down alarm cooling period ,"Currently the Scale down alarm cooling period  is 60sec 
AWS team has recommended to have Scale down alarm cooling period  is 300sec for smooth scale down . Please perform the test to check the impact of  increased Scale down alarm cooling period  in all the ecs service configuration."
Performance recommendation for Service Healthcheck grace period ,AWS team has recommended to have Service Healthcheck grace period 60 seconds. Please perform the test to check the impact of adding Healthcheck grace period in all the ecs service configuration. 
Performance recommendation on the scaling policy ,"Implement ECS service auto scaling based on percentage-based task scaling rather than fixed task count. This will ensure more adaptive scaling behavior, improving responsiveness to dynamic workloads across environments (e.g., dev, QA, prod) while reducing the need for hardcoded thresholds.



h3. *Percentage-Based ECS Auto Scaling Alarms: Strategy Overview*

h4. *Current Setup – Absolute Count:*

* Example:
** Scale out when {{CPUUtilization > 70%}} for 5 minutes
** Minimum of 2 tasks, maximum of 10 tasks
** Step scaling adds 1 or 2 tasks per alarm

Proposed Setup – Percentage-Based:

* Instead of saying “add 2 tasks,” scale based on *% of current task count*, e.g., *increase by 50% of current tasks*.
* Useful when service traffic fluctuates frequently or when service is deployed across multiple environments with varying baseline needs."
Perf test for wrapper changes for node-red functionalities,"As we are implementing wrapper changes (i.e. dynamically executing node logic instead of custom executor) we’ll need to compare performance before and after our changes.

More details can be find on parent card"
Performance testing for authorizer,…
Performance testing for lynkup endpoints,Performance testing should be conducted to [https://lynkup.readme.io/reference/createdelivery|https://lynkup.readme.io/reference/createdelivery|smart-link]  these endpoints since we are introducing additional check for XSS
"Perf test for DM- W2G jira (DL-55501, DL-55012, DL-55506)","[https://delivery-solutions.atlassian.net/browse/DL-55501|https://delivery-solutions.atlassian.net/browse/DL-55501|smart-link] 

[https://delivery-solutions.atlassian.net/browse/DL-55012|https://delivery-solutions.atlassian.net/browse/DL-55012|smart-link] 

[https://delivery-solutions.atlassian.net/browse/DL-55506|https://delivery-solutions.atlassian.net/browse/DL-55506|smart-link] "
Update PG indexes to make them covered queries,"Our current pg queries does not have covered indexes. it does index scan + table access to query the data from table. With covered queries, it will be index only scan and table access will be eliminated. This may increase index storage but will be much quicker than current setup.

*For Zones:*
*Current index:*

{noformat}CREATE UNIQUE INDEX 
ON postal_code_zones_idx on postal_code_zones (destination_postal_code, source_postal_code, tenant_id, provider){noformat}

*Proposed index:*

{noformat}CREATE UNIQUE INDEX 
ON postal_code_zones_idx on postal_code_zones (destination_postal_code, source_postal_code, tenant_id, provider)
INCLUDE services;{noformat}

*For Extended Postal Codes:*

*Current index:*

{noformat}CREATE UNIQUE INDEX 
ON extended_postal_codes_idx on postal_code_zones (postal_code, tenant_id, provider){noformat}

*Proposed index:*

{noformat}CREATE UNIQUE INDEX 
ON extended_postal_codes_idx on extended_postal_codes (postal_code, tenant_id, provider)
INCLUDE type;{noformat}

*For Rates:*

*Current index:*

{noformat}CREATE UNIQUE INDEX 
ON rates_idx on rates (service_id, zone, tenant_id, weight, provider, version, based_on){noformat}

*Proposed index:*

{noformat}CREATE UNIQUE INDEX 
ON rates_idx on rates (service_id, zone, tenant_id, weight, provider, version, based_on)
INCLUDE rate;{noformat}

*For rates_version_mapping:*

*Current index:*

{noformat}CREATE UNIQUE INDEX 
ON rates_version_mapping_idx on rates_version_mapping (service_id, zone, tenant_id, weight, provider, version, based_on){noformat}

*Proposed index:*

{noformat}CREATE UNIQUE INDEX 
ON rates_idx on rates (service_id, tenant_id, provider, based_on)
INCLUDE active_version;{noformat}"
Performance Test for Onboarding Service Memory Leak <DL-55238>,
Performance Check for webhook Queues (DL-9485),
"Performance testing Roadie, Uber and DD webhooks","* smart-scaling lambda should be tested in performance test
* hookrecievedAt  and createdAt - should be used to check delay in architecture
* test for live webhooks should work as expected
* Queue backlog metrics"
Internal Load Testing in Prod for W2G (Test 2),"h3. Load Test Details

||*Title*||*Description*||
|Load Test|100 RPS (5 minutes), 250 RPS (5 minutes), 450 RPS (5 minutes)|
|Environment|Production|
|Provider|UPS (Mocked)|
|Track Alert Subscription|Disabled|
|Duration|15 minutes|
|Time Window|Non Peak Hours|
|Impact|Low impact as this will be done in non-peak hours|
|Rate Limits|250 RPS Rate Limit in both region on the tenants considered for Load TEst|
|Monitoring|Performance Team|
|Execution|Performance Team|
|Infra Scale Up and Scale Down|Infra team|

h3. 
PFB the infra requirements - 

_Note:_
_EC2's minimum is regular numbers and maximum is ware2go's numbers_
_ECS's minimum is ware2go's numbers and maximum is ware2go's numbers_

*Oregon* -

* Onboarding service:
** Min - 50 containers, 2 t3a.medium servers
** Max - 50 containers, 25 t3a.medium servers
* API:
** Min - 100 containers, 4 m6i.large servers
** Max - 100 containers, 50 m6i.large servers
* Business Rules:
** Min - 40 containers, 3 m6i.large servers
** Max - 40 containers, 15 m6i.large servers
* Labels service:
** Min - 33 containers, 4 t3a.xlarge servers
** Max - 33 containers, 33 t3a.xlarge servers
* Providers service:
** Min - 45 containers, 2 t3a.medium servers
** Max - 45 containers, 15 t3a.medium servers
* Smart Windows:
** Min - 25 containers, 3 t3a.medium servers
** Max - 25 containers, 13 t3a.medium servers

*North Virginia* -

* Onboarding service:
** Min - 50 containers, 2 t3a.medium servers
** Max - 50 containers, 25 t3a.medium servers
* API:
** Min - 100 containers, 4 m6i.large servers
** Max - 100 containers, 50 m6i.large servers
* Business Rules:
** Min - 40 containers, 3 m6i.large servers
** Max - 40 containers, 15 m6i.large servers
* Labels service:
** Min - 33 containers, 4 t3a.xlarge servers
** Max - 33 containers, 33 t3a.xlarge servers
* Providers service:
** Min - 45 containers, 2 t3a.medium servers
** Max - 45 containers, 15 t3a.medium servers
* Smart Windows:
** Min - 25 containers, 3 t3a.medium servers
** Max - 25 containers, 13 t3a.medium servers"
Do a gap assessment with performance admin panel and plan for self service generic tests,
Perf Load testing for Dynamic DSP Place order,
Perf Load testing for Dynamic DSP Estimate,
Perf Load testing for the workflow-service with the STS & APS flow,
Perf Load testing for the workflow-service with the dummy flow,
Internal Performance test on Prod,
Internal Load Testing in Prod for W2G,"h3. Load Test Details

||*Title*||*Description*||
|Load Test|100 RPS (5 minutes), 250 RPS (5 minutes), 450 RPS (5 minutes)|
|Environment|Production|
|Provider|UPS (Mocked)|
|Duration|15 minutes|
|Time Window|Non Peak Hours|
|Impact|Low impact as this will be done in non-peak hours|
|Rate Limits|250 RPS Rate Limit in both region on the tenants considered for Load TEst|
|Monitoring|Performance Team|
|Execution|Performance Team|
|Infra Scale Up and Scale Down|Infra team|

h3. 
PFB the infra requirements - 

_Note:_
_EC2's minimum is regular numbers and maximum is ware2go's numbers_
_ECS's minimum is ware2go's numbers and maximum is ware2go's numbers_

*Oregon* -

* Onboarding service:
** Min - 50 containers, 2 t3a.medium servers
** Max - 50 containers, 25 t3a.medium servers
* API:
** Min - 100 containers, 4 m6i.large servers
** Max - 100 containers, 50 m6i.large servers
* Business Rules:
** Min - 40 containers, 3 m6i.large servers
** Max - 40 containers, 15 m6i.large servers
* Labels service:
** Min - 33 containers, 4 t3a.xlarge servers
** Max - 33 containers, 33 t3a.xlarge servers
* Providers service:
** Min - 45 containers, 2 t3a.medium servers
** Max - 45 containers, 15 t3a.medium servers
* Smart Windows:
** Min - 25 containers, 3 t3a.medium servers
** Max - 25 containers, 13 t3a.medium servers

*North Virginia* -

* Onboarding service:
** Min - 50 containers, 2 t3a.medium servers
** Max - 50 containers, 25 t3a.medium servers
* API:
** Min - 100 containers, 4 m6i.large servers
** Max - 100 containers, 50 m6i.large servers
* Business Rules:
** Min - 40 containers, 3 m6i.large servers
** Max - 40 containers, 15 m6i.large servers
* Labels service:
** Min - 33 containers, 4 t3a.xlarge servers
** Max - 33 containers, 33 t3a.xlarge servers
* Providers service:
** Min - 45 containers, 2 t3a.medium servers
** Max - 45 containers, 15 t3a.medium servers
* Smart Windows:
** Min - 25 containers, 3 t3a.medium servers
** Max - 25 containers, 13 t3a.medium servers"
Align Performance Environment Configuration with Production Environment,"We need to check each and every component of performance environment and see make a list of all the components which do not match the configuration on production environment. Then make sure perf is updated as per prod.

*_Needed in both regions. Perf should have all the services, RDS etc as it is in both the regions._*
This includes:

# EC2 instance types
# RDS DB, MongoDB and Redis instance types / tiers (of both primary and secondary nodes)
# Replica nodes counts
# ECS, EC2 instance counts (Both region)
# CPU, Memory - soft limit, hard limit on containers
# Autoscaling alarms
# API Gateways
# Authorisers
# Load Balancers
# Security Groups
# Rate Limits
# AZs / Task placement strategy
# Capacity providers
# Mongo DB - primary DB size, replicas for Main DB, Log DB, Returns DB



On top of this, we have to make sure we do not have Cloudwatch insights and Cloudwatch logs on any of the services on performance. "
Client Performance test W2G - Monitoring,
Performance test on Ware2Go use case when shipOptions are not provided (Rate Shopping),"Performance test on Ware2Go use case when shipOptions are not provided

Proposed provider will not be used if shipOptions is not provided, as we have observed that the response times are high when proposed provider is not provided, hence we have to provided additional resources to support this use case. We would like to optimise this to optimise cost and resources before Ware2Go moves into the next phases of the onboarding activity and gets more customer live to Lynkup.

The following cards have been setup for the optimisation purposes:
[https://delivery-solutions.atlassian.net/browse/DL-53364|https://delivery-solutions.atlassian.net/browse/DL-53364|smart-link] 

[https://delivery-solutions.atlassian.net/browse/DL-53365|https://delivery-solutions.atlassian.net/browse/DL-53365|smart-link] 

[https://delivery-solutions.atlassian.net/browse/DL-53188|https://delivery-solutions.atlassian.net/browse/DL-53188|smart-link] 

Once the optimisation is done we can test the feature end to end by not providing shipOption and see if resources required are optimised, API is providing expected response times and the services are stable at 250 RPS to 450 RPS.


Calibrate infra numbers for prod if needed."
Performance Test for AloYoga,"|Timestamp|Email Address|Read and Agree to Rules of Engagement|Type of Test|Scope Definition|Expectations / Desired Outcomes|Expected RPS|Expected Latency|Requested Date & Time|Requested Run Time|Timezone|
|3/4/2025 3:00:56|sandeep.jacob@aloyoga.com|Agree|Performance Test|We need to perf test the delivery assurance api|Modified /api/v2/deliveryAssurance to use ""store-boundary-dsp"" and need to ensure that the API performs well under load while effectively utilizing caching|5|800|3/4/2025|3 hours|PST|"
"Performance Testing Required : E2E Simulation Flow : Upload, Processing, Downloading & Email","To run performance testing for the components being used in Simulation Tool. 

A simulation tool is being built ideally to simulate (run) the real world rate call flow and capture various parameters form the response to collate and provide in a reporting format. These records count would be upto 500k (initially it was 1m)  

Large Dataset testing is required.

To provide “simulation” ability, this is being requested. 

This card should be testing the End 2 End flow of the Simulator tool.

Flow : 

Upload File (500k Records) > Process File (run through orchestration call, custom rates & Custom transit  time flows > Collate/Create File Data > Download File > Email File. "
Calibrate the final infra numbers for Ware2Go use case,"We have to calibrate the infra servers numbers to support:

* 200 RPS
* 450 RPS  (This is the traffic we observed by customer during their testing)

The P95 response time should be as low as possible (not more than 5 seconds). 

These infra numbers will be used by the Infra team for scheduled scaling on production.
This should be only for the pilot launch. We will monitor it for a while and after which we will bring it back if this infra is not required."
Calibrate services to serve W2G traffic in Production,Calibrate services to serve W2G traffic in Production
Performance test of Ware2Go load with Endurance,
Client Performance test 2,To be scheduled.
Assess SLA Impact of Custom Write Concern Implementation,"h3. We will evaluate write performance by checking the response time of key services: 

h3. *Webhooks, API CRON, Place Order, BR MS, and API MS*. 

h3. This will help us assess the impact of multi-region writes.

we will update the *app URI* with an appropriate *multi-region write concern*

* {noformat}db.collection('orders').insertOne({ orderId: 123, status: 'Pending' }, { writeConcern: { w: ""twoRegions"" } });{noformat}"
Client Performance Test,
Investigate WebhookApiGatewayDR timeouts,"Investigate WebhookApiGatewayDR timeouts that caused p1 alert.

Log Links:

# [https://onenr.io/0qwydgPepQn|https://onenr.io/0qwydgPepQn]
# [https://onenr.io/01wZN6WqKw6|https://onenr.io/01wZN6WqKw6]
# [https://onenr.io/0OwvdP80Njv|https://onenr.io/0OwvdP80Njv]
# [https://onenr.io/0qwydgzeXQn|https://onenr.io/0qwydgzeXQn]
# [https://onenr.io/0Zw0kpX6nQv|https://onenr.io/0Zw0kpX6nQv]
# [https://onenr.io/0bRmLVGNWwy|https://onenr.io/0bRmLVGNWwy]
# [https://onenr.io/0BQrkm4K2wZ|https://onenr.io/0BQrkm4K2wZ]"
Perf Load testing for Custom Executor,"Need to do Load performance testing for custom executor. 


*Requirements given on 14th January:*
Need to do Place Order End to End with 1000 flows at 1x and 5x load with code on API MS.



*Requirements given on 20th January:* 
Need to do Place Order End to End with 1000 flows at 1x and 5x load with code on Provider MS.



*Requirements given on 21st January based on 570 ms:*

Need to do Place Order End to End with 1000 flows with API MS with new library changes

Need to do Place Order End to End with 1000 flows with Provider MS with new library changes

Need to do Place Order End to End with *10 flows* at 1x and 5x load with code on Provider MS.

Need to do Place Order End to End with *100 flows* at 1x and 5x load with code on Provider MS. (_do it for 100 only if 10 flows matches the SLA ~ 500 ms_)"
Performance Test for Alo Yoga,"|Timestamp|Email Address|Read and Agree to Rules of Engagement|Type of Test|Scope Definition|Expectations / Desired Outcomes|Expected RPS|Expected Latency|Requested Date & Time|Requested Run Time|Timezone|
|1/6/2025 23:26:21|[sandeep.jacob@aloyoga.com|mailto:sandeep.jacob@aloyoga.com]|Agree|Performance Test|We need to test our carrier service and validation API which internally calls the delivery assurance API -> api/v2/deliveryAssurance|Meets the benchmark of 40 RPS|40|500|1/27/2025|3|PST|"
Performance benchmarking for Client Facing APIs (For Sandbox S2025-OP-105.0.0),
Performance of all APIs (For Sandbox S2025-OP-105.0.0),
Revisit Place Order flavours in generic performance test,"Currently the p95 response time in generic performance tests is seen somewhere around to be 490 ms. However sometimes this goes above 500 ms, which is above our SLAs for place order. This needs some steps like reiterations and/ or DB cleanup to be under 500 ms. We should revisit these flavours and find a solution which can constantly keep this around 450ms or under so that we do not need reiterations.

Possible solutions:

# *Increase the sample size*. Currently the duration of test is around 10 minutes and at 5x traffic this leads to around 1700 samples in 10 minutes. This sample size may be too small which can cause the p95 to deteriorate. We can either increase the duration or throughput to increase the sample size however this can cause the total duration of generic test to increase even further which is already too high.
# *Create new tenants*. We may create new tenants specifically for these flavours. The tenant currently used has lots of setup regarding stores, DSPs which can cause additional latency. Creating a separate tenant with just basic configuration will remove all of this extra data."
"Ware2Go Load Test on Rates (Shipping), PO (Shipping) and Labels APIs","|11/19/2024 22:39:16|[chris.d@ware2go.co|mailto:chris.d@ware2go.co]|Agree|Performance Test|DS to stress test their system to demonstrate that they can receive, rate shop, and return labels to Logiwa so as not to impact warehouse operations. Logiwa will send thousands of requests per day and many of them will come between 2 EST and 9EST as we have 30 warehouses across the country|DS demonstrates that they can return labels to Logiwa in a manner that does not impact warehouse operations|2500|1|11/19/2024|4|EST|

[https://docs.google.com/spreadsheets/d/1yPbLK44YRN_7KyIaU9rWDS7ao9s2e48mR8oRcC3YaVc/edit?gid=441635978#gid=441635978|https://docs.google.com/spreadsheets/d/1yPbLK44YRN_7KyIaU9rWDS7ao9s2e48mR8oRcC3YaVc/edit?gid=441635978#gid=441635978|smart-link] "
Performance test for DL-49215,"Performance test after the implementation of the orderEstimates entity, and the migration of the orderEstimates data from tenant DB to multi-tenant DB."
Performance Testing Required: Rate API in new Infra,"To run performance testing for the components being used in Simulation Tool. 

A simulation tool is being built ideally to simulate (run) the real world rate call flow and capture various parameters form the response to collate and provide in a reporting format. These records count would be upto 500k (initially it was 1m)  

Large Dataset testing is required.

To provide “simulation” ability, this is being requested. "
Perf Load testing for the Node Red Dynamic load and the flows execution.,"Need to do Load performance testing for Node-Red instance.



Execution details can be find here. (will update curl later).

[https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/1152712709/Node-red+Performance+Testing|https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/1152712709/Node-red+Performance+Testing|smart-link] "
Performance test for the temporary /eta endpoint in Pickup Service,Perform the perf and load/stress test on the /eta endpoint introduced in the pickup service
Performance test for DL-3747 and DL-2973,Since we have encrypted api key and provider credentials we need to check the performance of the application 
Only Prod - Make Store Boundaries Node highly available,"During the RCA of [https://delivery-solutions.atlassian.net/browse/DL-48784|https://delivery-solutions.atlassian.net/browse/DL-48784|smart-link] it was found that when one instance goes down, the Store Boundaries Service becomes unstable. Need to have a performance recommendation based on performance tests on the number of instances."
Performance Test for Naruto,Performance test for Naruto
Sally Beauty High Latency DA Calls,"+*This is an escalation from L2 to L3 for extended RCA*+

Sally is seeing increased latency with DA calls with both tenants in prod.

Slow api calls: [https://onenr.io/0bRm77XrrQy|https://onenr.io/0bRm77XrrQy]

single DA log link: [https://onenr.io/0vjA55eozjP|https://onenr.io/0vjA55eozjP]

Slow query: [https://onenr.io/0BR633a1GjO|https://onenr.io/0BR633a1GjO]"
Place Order Performance Testing,"Performance testing for place order, to ensure no increase in latency."
Performance Testing | DL-47536,
Verify communication service with PG Db ,"We have added some code in communication service .  if Postgress Db service got down middle of any task so our communication service will try to reconnect till 5 attempt and after that we are making container down .

So in the task we have to verify the same on QA by making the Postgress Db service down and test the same .

[https://delivery-solutions.atlassian.net/browse/DL-46381|https://delivery-solutions.atlassian.net/browse/DL-46381|smart-link] 



Steps (from [~accountid:62aad5226085950068af4d77] ):

# Start up perf postgres db
# Start up communication service perf
# Communication service should connect to the db
# Shut down perf postgres db
# Communication service should retry connection 5 times and then kill container
# Start up perf postgres db again
# New Communication service container should spawn up
# Communication service should connect to the db
# Just check above steps, no performance test is needed."
Prep Task for Michaels Load Test.,"

!image-20240927-084053.png|width=547,height=645,alt=""image-20240927-084053.png""!



||Scope Definition||Expectations / Desired Outcomes||Expected RPS||Expected Latency||Requested Date & Time||Requested Run Time||Timezone||
|Understand Latency between apps for producing shipping labels|Latency within 3.5 sec and handle sample volume 4000 labels/day or 170/hour|1|2|9/30/2024|72|CST|"
Check Negative Cases Via Perf Environment for Valhalla Failures - Edit Order Case and other places where Valhalla is integrated.,[https://delivery-solutions.atlassian.net/browse/DL-46530|https://delivery-solutions.atlassian.net/browse/DL-46530|smart-link] Need help to test this case
Performance Test for DL-45870,To check impact on PO.
Performance test for DL-38731,Handoff call - [https://drive.google.com/file/d/11KHfcGmQ3V7cUED_aTIDTJuCyToLWIMD/view|https://drive.google.com/file/d/11KHfcGmQ3V7cUED_aTIDTJuCyToLWIMD/view]
Prepare of BigLots Load Test,"{quote}*BigLots:*

""We are planning to do this load test on Sept 10th in Biglots QA website.  Please bring the DA API calls infra in pre-prod environment on 9th sept, so smoke testing can be done on 9th for 2 hours and the Load test can be done on 10th Sept.""{quote}

----

Test setup - 

* JMX to be used - big-lots load test JMX
* Branch - Sandbox for all services(Deploy if needed)
* Replicate Big Lots sandbox data to testing tenant
* Flavours - DA, SW and Rates
* +Check for new integrations/new APIs if any that big lots have started using. Mostly they would be same as present in JMX. Check the store count in Rates and SW calls. If there is a difference, update the same in JMX.+
* Rates and smart windows should use new zips for each request. Use the zips from the generic suite
* TPS is to be tested at - 
** +DA = 250 TPS+
** +SW = 15 TPS+
** +Rates = 15 TPS+
** +PO = 10 TPS+
* Add new flavour - SW with 1 store, with and without provider at 40 TPS
* Update threads and ramp up time to support this TPS
* Test duration is 30 mins, and the final test for sign-off should be 60 mins
* Pre-scale containers of Rates, SW, and DA if required
* Restore sandbox snap on perf
* Make necessary changes in performance authoriser
* Make sure that the testing tenant has these caching settings for DA - 
!image-20240905-045816.png|width=1895,height=988,alt=""image-20240905-045816.png""!

Important - 

* All the APIs should use the mocked DSP that we have created - [https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/784597187/Implementation+of+Mock+Lambda+For+BigLots|https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/784597187/Implementation+of+Mock+Lambda+For+BigLots|smart-link] 
* Before starting the test verify every API, check if the mocked DSP is used, and check if any billable request is being made and fix it.

Things to observe and document - 

* The number of containers need to support the load test
* RDS metrics
* Redis metrics
* Mongodb metrics
* Services metrics
* Check for container deregistration"
Fault Tolerance with Cron Service Report,"*Source:* [https://delivery-solutions.atlassian.net/browse/DL-9167|https://delivery-solutions.atlassian.net/browse/DL-9167|smart-link] 

This requirement is to understand how *Fault Tolerant* and *Scalable* is *Cron Service* to Solution the above, as the above card’s operation is business critical - having this information is crucial for the solution."
Test Valhalla Auto-scaling and provide infra recommendations,"Auto-scaling part of this card - [https://delivery-solutions.atlassian.net/browse/DL-30954|https://delivery-solutions.atlassian.net/browse/DL-30954|smart-link] 

# PO with the driving distance
# PO with RO flow pointing to Valhalla - Make sure we have at least 80% orders as routeOptimised
# Autoscaling numbers - Min, Max, Desired
# Instance type recommendation
# Memory value in TD
# Time required for a new task to spawn in Valhalla ECS.
# ECS Endpoint - [-https://valhalla-test-np.deliverysolutions.co-|https://valhalla-test-np.deliverysolutions.co/status][  https://valhalla.deliverysolutions.co|https://valhalla-test-np.deliverysolutions.co/status]
# OSRM VS Valhalla metrics comparison"
Ensure geocoding is not happening in performance tests,"Logiwa is not sending latitude and longitude, hence we are geocoding. This increases latency in the system along with massive billing. Hence, we should be entering static values in the template for performance environment to ensure no geocoding happens"
Check the existing snapshot migration pipeline in the old portal,"# initiate the snapshot should work as expected for Dev, QA, Sandbox
# migration should work as expected.
# Currently for sandbox snapshot, we cannot migrate an existing snapshot in US work hours. This rule should only apply to taking the snapshot and not migrating an existing snapshot. (to be confirmed by [~accountid:5ee75f40e145af0ab47dacb8] )
# Should allow the migration to rreturns db as well (from general qa & sandbox, returns qa & sandbox and perf. )"
Performance Evaluation for saving package level Barcodes and QR codes - DL-38914,"Performance Evaluation for saving package level Barcodes and QR codes - [https://delivery-solutions.atlassian.net/browse/DL-38914|https://delivery-solutions.atlassian.net/browse/DL-38914|smart-link].

Branches - [https://delivery-solutions.slack.com/archives/C07BQ0T4068/p1721046092032329|https://delivery-solutions.slack.com/archives/C07BQ0T4068/p1721046092032329|smart-link] "
Performance Testing - Iteration 2 for DL-34481 [Provider Service],Performance Testing - Iteration 2 for DL-34481 [Provider Service]
Action Items post Performance Test observations of DL-36788 ,"* POC on Accelerated Transfer for S3 operations since using aws-sdk to fetch directly from S3 has not shown any improvement in performance. [https://aws.amazon.com/s3/transfer-acceleration/|https://aws.amazon.com/s3/transfer-acceleration/|smart-link]
* Also test the labels flavours on compute optimised servers to observe any difference in performance of the label services.
* Resolve dns resolution latency by using http connection polling. [https://delivery-solutions.atlassian.net/browse/DL-14872|https://delivery-solutions.atlassian.net/browse/DL-14872|smart-link] [https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/583630879|https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/583630879|smart-link] 

 "
Calibrating Labels Performance Suite,"* Make following changes to the labels suite:
** Keep only one worst case scenario of 30 packages shipping flavours, bouclair has some orders with 30 packages we should at least have this scenario whenever we conduct our stress tests.
** Change existing 30 packages shipping flavours to 8 packages shipping flavours 
** Replace existing 10 packages delivery flavours and 1 package delivery flavours.
* Test all labels load test scenarios on current V2 Labels Traffic 1x, 5x and 25x. This is going to be our new benchmark going forward.
* V2 vs V3 Service comparison would be needed at current V2 Labels Traffic at 1x.
* Update generic and endurance test traffic with respect to current V2 Labels Traffic."
Investigate uninstrumented traces in distributed tracing found during labels performance test.,"Investigate uninstrumented traces in distributed tracing found during labels performance test.

[https://onenr.io/0nQxOZyMajV|https://onenr.io/0nQxOZyMajV]

!image-20240620-122311.png|width=1571,height=368,alt=""image-20240620-122311.png""!"
Performance Testing for Nearest Location - Return Location Orchestration,
Performance Test: 2' Extension Labels - Place Order Latency Check,"[https://delivery-solutions.atlassian.net/browse/DL-29721|https://delivery-solutions.atlassian.net/browse/DL-29721|smart-link] 

We have made changes in the PO flow for this card. Need to check if the PO response time has not increased.

Need to check v3 Label generation with extension as well."
Create a new relic dashboard for DL-35618,Create a new relic dashboard which mentions the public APIs used by tenants and have phone number in them. This is required for: [https://delivery-solutions.atlassian.net/browse/DL-35618|https://delivery-solutions.atlassian.net/browse/DL-35618|smart-link] 
Performance test for Labels after refactor to fetch directly from S3,"* Test all labels load test scenarios on the same traffic as existing benchmark that is PO traffic 1x, 5x and 25x. This test will be used compare improvement from last benchmark."
Performance Testing  for DL-34481 [Provider Service],"Performance Testing needs to be performed for the following PRs raised - 

API MS - [https://bitbucket.org/deliverysolutions/api.deliverysolutions/pull-requests/14248|https://bitbucket.org/deliverysolutions/api.deliverysolutions/pull-requests/14248|smart-link] 
Estimate MS - [https://bitbucket.org/deliverysolutions/estimates-service/pull-requests/2132|https://bitbucket.org/deliverysolutions/estimates-service/pull-requests/2132|smart-link] 
Library - please check the feature branch - S101_dl34481_provider-connector_beta for src code review and [https://bitbucket.org/deliverysolutions/ds-provider-connector/pull-requests/17|https://bitbucket.org/deliverysolutions/ds-provider-connector/pull-requests/17|smart-link]  PR for unit test cases code review.

Performance Test of the provider service needs to be done in isolation as well as end to end test needs to be performed with Rates, DA and API microservice."
POC of Alerts on Anomaly Detection via NewRelic,"h1. Anomaly detection

Anomaly detection allows your team the most versatility when detecting unusual behavior in your system. Anomaly detection gives your team the ability to alert on any entity or signal and to adjust and optimize your sensitivity thresholds. Anomaly detection uses the same streaming-alerting pipeline as static threshold alerts and shares the same advanced tuning settings. This ensures that the stream processing is aligned to your telemetry signal's characteristics to reduce false alerting.

[https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/anomaly-detection/|https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/anomaly-detection/|smart-link] "
Script to create dummy labels for labels V3,
Performance Test for Post Dispatch Exception (Exception Management) Refactor DL-32362,
Notification Service Revamp Phase 2 Performance Test,Communication webhooks performance testing should be conducted as part of this task for scheduled and immediate alerts.
Performance Test for Pre Dispatch Exception (Auto Retry) Refactor DL-5840,* Note that we also need a before/after comparison in this card
Performance test for worker pool,"# 1x PO Traffic with DSP + PDF/ZPL + 4 x 6 ( 203 dpi ) *- currently timing out - worker threads for better CPU utilization*
# 1 package DSP + PDF
1 package DSP + ZPL
1 package DS + PDF
1 package DS + ZPL
# 1x TPM of v2 label on prod → v2 vs v3
# Run labeler performance suite

We need to set a script that will enable us to create unique dummy DSP label images that shall help us create mock providers' responses that can be used to set up orders in our performance tests. This shall help us remove dependency on Providers setup orders required for the performance test."
Performance Test - Labels v3 End to End,Performance Test - Labels v3 End to End
Notifications Revamp Phase-1 performance test [Bug Fixes],
Smart Scaling Lambda Setup for Messaging Service,We will need to set up Smart Scaling Lambda for Messaging Service as of now the service scales only based on CPU and Memory. We can also scale it based on queue backlog.
Performance Analysis of Notification Timer Revamp,
Performance analysis of Place Order flow with Pre-Dispatch Exceptions,
Performance analysis of Scheduled Orders,
Performance Test - Labels v3 [Puppeteer & JSPdF POC],
Add 'pilot-order-db' in Repository library and publish in QA services,"To check the changes in the pilot card([https://delivery-solutions.atlassian.net/browse/DL-29360|https://delivery-solutions.atlassian.net/browse/DL-29360|smart-link]), we need to add support to point some tenants to the pilot-order-sb.

The following things are to be taken up - 

[~accountid:62b548d7f38b4dcf73dae06c] - 

* Will provide a list of tenants to be added to the if-condition
* The list should include - 
** Tenant(s) that will be used by QA for testing - [~accountid:61d802b29ee70a0068891026] Will provide this
** 2 tenants from Endurance Suite. These tenants will be first migrated from Sandbox to QA
** An additional dummy tenant

[~accountid:62aad5226085950068af4d77]  - 

* Get the list of all the MSs that will need repository version updates and deployment. Get this list reviewed.
* Code changes in the Repository Library
* Inform on #ds-dev-tester_channel about the activity and tenants
* Get the PRs merged on QA


Code snippet for reference - 

{noformat}export class OrderRepositoryBuilder {
  constructor() { }

  static async build(tenantId: string, collectionOptions?: CollectionOptions): Promise<OrderRepository> {
    if([<list of test tenant's tenantId>].includes(tenantId)) {
           let db = await getMongoDbConnection(`pilot-order-db`, process.env.DB_URL))
            return new OrderRepository(db, collectionOptions);
    }
    
    const tenantDb = await getTenantDbConnection(tenantId);

    if (tenantDb instanceof InternalServerException) {
      throw tenantDb;
    }

    return new OrderRepository(tenantDb, collectionOptions);
  }
{noformat}"
Performance Testing for Notifications and Alerts,Performance Testing for Notifications and Alerts after the integration of new service
Performance testing of the RO engine,Reference - [https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/717586462/Google+OR-Tools|https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/717586462/Google+OR-Tools|smart-link] 
Setup DAP in performance to completely point to performance environment,Setup DAP in performance to completely point to performance environment
Performance Testing of Optimised Route Plans,
Performance Evaluation of Memory Leak Issue in Communication Service,Issue Replication and Performance Evalution for [https://delivery-solutions.atlassian.net/browse/DL-25226|https://delivery-solutions.atlassian.net/browse/DL-25226|smart-link] 
Performance retest for DAP with fixed issues,"* We have communicated the issues to [~accountid:5e01a9377a22c90da0c4adf7] and the team. We will be doing a retest once the issues are resolved.

* Issues reported - [https://delivery-solutions.atlassian.net/browse/DL-26157?focusedCommentId=52838|https://delivery-solutions.atlassian.net/browse/DL-26157?focusedCommentId=52838|smart-link] 

* We will be pointing completely to sandbox resources(including onboarding service) for these tests as internal sandbox URLs are called.
* Please conduct the tests in non-US hours(11 am to 5 pm IST)"
Performance Environment Setup For Micheals,"Performance Environment Setup For Micheals

* Need to replicate the latest sandbox cluster to the performance cluster
* Deploy the latest sandbox code to the performance
* Make sure that the pendingReleaseOrder Cron is working as expected.
* Test E2E Micheals integrations - 
** PO
** Create Estimates
** Tenant webhooks
* Do a load test of PO and Edit Order at 35 RPS
* Tenant's Webhooks should work as expected."
Migrate NLB URLs to ALBs in performance environment,Change the config.perf.json file and remove internal URLs from the micro services.
Performance tests for Predictive ETA/ETD - [Third Iteration],"We need to test the prediction engine service directly to test the performance of the service, this needs to be done in 2 steps:

# We will perform a 100 TPS load test on the curls provided the the AI/ML team to the service provides results within a minimum time duration. Expected latency should be <100 ms.
[https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/754581615/PROD+curl+request+and+response+time|https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/754581615/PROD+curl+request+and+response+time|smart-link] 
# We performed an end-to-end load test on 22nd June, we need to refer to the test setup used for that test and replicate the requests to send to Cognida Service via the prediction engine library for each of our scenarios and do a load test directly on the Cognida Service with the same RPS that we had executed in our end to end test. 
[https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/696844313/Cognida+Test+22nd+June|https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/696844313/Cognida+Test+22nd+June|smart-link] 

We will also do a reiteration of the end-to-end prediction ETA/ETD test by increasing the CPU and Memory of the tasks to see whether we are able to see any improvements in the latencies.

Test Setup: [https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/689897955/Cognida+Test|https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/689897955/Cognida+Test|smart-link] "
Benchmarking of returns APIs by performance test,"Once the suggested changes to improve the performance of returns are done, the APIs are needed to be tested again and benchmarked."
Performance Test for DAP at 5 TPS,"* We want to know the SLAs for All the APIs exposed to DAP. 
* The load expected on it are minimal for now. 
* SLA that we have provided to Customer is 10 seconds 
* [~accountid:624160d8f407980070546df5]  will attach Postman Collection for all APIs on the card. 
"
Review performance test suite- Q4 - 2024,
Endurance Test - Feb-24,
Endurance Test - Jan-24,
Performance Test Setup for Big Lots Test (19-Oct-23),"|Scope Definition|Expectations / Desired Outcomes|Expected RPS|Expected Latency|Requested Date & Time|Requested Run Time|Timezone|
|80,000 concurrent vusers, 6 hours|Make DS - Performance Test environment available for the load test|167|150|10/3/2023|6|EST|"
Create a framework for automated infra changes through AWS SDK scripts,"Approach:

Performance admin panel uses aws sdk scripts to update resources. The question is whether we can do the same to update AWS resources through it during regular releases. There can be 2 approaches to the same:

# Create a list of common actions (AWS SDK snippets) that can be used to get a job done. This will be used across environements and aws accounts
# Create a migration repo like structure where every release, a set of infra migrations are written which will need to be executed. Here, also we have to decide how the variables are passed to the scripts"
Performance of all APIs  (For Sandbox S2023-DM-40.0.0),
Ability to change launchTemplate version from admin panel,
Endurance Test - Sept-23,
Performance benchmarking for Client Facing APIs  (For Sandbox S2023-DM-40.0.0),
Performance benchmarking for Client Facing APIs  (For Sandbox S2023-IA-39.0.0),
Endurance Test - Jul-23,
Stress Test PO and Web hooks by 600 RPS of PO traffic via batching processor,"*Background -*

* We need to simulate a test where POAsync, ProcessOrderAsync and Web hooks are simulated at 1000 RPS and PO is fired at 600 RPS from batching-processor

----

*Test-cases -*  

* Check stability at 1000TPS of placeorderAsync, processOrderAsync and web hooks
* Check stability of PO at 600 RPS, this traffic should be simulated with batching-processor
* 4 hour test

----

*Test setup -*

# No DB cleanup
# UPS load test JMX for 4 slots

----

*Test monitoring -*

# New Relic monitoring to check TPS being hit
# UPS Cloudwatch dashboard
# MongoDB performance metrics
# RDS metrics 

----

*Results reporting -* 

# Observations and red flags"
Integration Load Test With Roadie,Integration Load Test With Roadie
Load test with self-healing feature [post-dispatch],"*Background -*

* To do a load test with cancel clone.[https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/484114921/Self+Healing|https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/484114921/Self+Healing|smart-link]  

----

*Test-cases -*

# Check place-order TPS and response times in this scenario
# Check the autoscaling.
# Check the cpu and memory utilization. 

----

*Test setup -*

# No DB cleanup
# Create orders already beforehand, setup the orders such that 20% of the orders are marked for post dispatch self healing
# Setup post dispatch settings to simulate the above scenario

----

*Test monitoring -*

# New Relic monitoring to check TPS being hit
# MongoDB performance metrics
# Cloud watch metrics

----

*Results reporting -*

# Observations and red flags"
UPS load test for 24 hours(1 week of operations),"*Background -*

* Vulcan will have traffic for 4 hours. With this card, we want to be ready for entire weeks operation traffic. 

----

*Test-cases -*

# UPS load test for 24 hours
# Check place-order TPS and response times in this scenario
# Check the autoscaling.

----

*Test setup -*

# Upgrade the current setup to support this [https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/686785465/UPS+DS+integration+test+checklist|https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/686785465/UPS+DS+integration+test+checklist|smart-link] for 24 hours.
# No DB cleanup
# Use the same load as mentioned here - [https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/686785465/UPS+DS+integration+test+checklist|https://delivery-solutions.atlassian.net/wiki/spaces/standards/pages/686785465/UPS+DS+integration+test+checklist|smart-link] 

----

*Test monitoring -*

# New Relic monitoring to check TPS being hit
# Check the cpu and memory utilisation. 
# MongoDB performance metrics

----

*Results reporting -*

# Observations and red flags"
Load test with self-healing feature [pre-dispatch] - Alternate DSP,"*Background -*

* To do a load test for pre-dispatch self-healing scenarios with alternate DSPs

----

*Test-cases -*

# Check place-order TPS and response times in this scenario
# Check the autoscaling.
# Check the cpu and memory utilization. 

----

*Test setup -*

# No DB cleanup
# Create orders in such a way that 20% of orders fail to get placed with our DSP and are forced to retry with an alternate DSP via pre-dispatch settings

----

*Test monitoring -*

# New Relic monitoring to check TPS being hit
# MongoDB performance metrics
# Cloud watch metrics

----

*Results reporting -*

# Observations and red flags"
API Rate limit stress test,"*Background -*

* Currently we don’t have any rate limit set in performance. Set the rate limit in aws for a particular tenant. 
** api gateway > usage plans > create a plan > add a tenant.

----

*Test-cases -*

# Rate limit error response when a rate limit is added and the RPS exceeds that limit.
# No rate limit error without that limit for tenant.

----

*Test setup -*

# No DB cleanup
# UPS load test with 100RPS of PO
# Enable gateway logs
# Simulate a randomiser to throw errors in DSP placeorder lambda

----

*Test monitoring -*

# New Relic monitoring to check errors
# Cloudwatch Monitoring

----

*Results reporting -*

# Observations and red flags"
Figure out and test infra scale-up and scale-down ,"*Background -*

* We don't have the exact scaling numbers for Vulcan. We need to find out the Min, Max, and Desired container counts for all the services involved in Vulcan. This will be a similar activity as that performed here - [https://delivery-solutions.atlassian.net/browse/DL-12572|https://delivery-solutions.atlassian.net/browse/DL-12572|smart-link] 
* Note that scale-down policies need to be proper and as accurate as possible.

----

Testing strategy for this card will be to run the full load will all services scaled up and check the container insights for all services. We reduce the number of containers if the memory and CPU utilization is low, and we increase the number of containers if the memory and CPU utilization are high.

----

*Test-cases -*  

# Figure out auto-scaling thresholds needed to scale up and down
# Check scale-up and scale-down of services for 1 slot
# Check scale-up and scale-down of services for all slots
# No deregistrations should be observed, response times should not be affected

----

*Test setup -*

# No DB cleanup
# Enabled container insights of the target service.
# Start with these scaling numbers and increase/decrease the container counts and instances 
!b076d76c-6662-49c5-839d-2dd060a2b68d#media-blob-url=true&id=1bdeab05-d003-4bcc-9e28-f65e706242ae&collection=contentId-694550682&contextId=694550682&height=380&width=769&alt=|width=1537,height=760!
# Short tests with UPS load(1000 RPS)

----

*Test monitoring -*

# Check the average memory and CPU utilization. Reduce the container counts if memory/CPU util is very low

----

*Results reporting -* 

# An Excel sheet with final scaling numbers and auto-scaling thresholds"
Endurance test with Vulcan flow,"*Background -*

* Endurance test with 5x prod along with UPS use case test running parallel.

----

*Test-cases -*

# Check place-order TPS and response times in this scenario (for both tests)
# Check the autoscaling.

----

*Test setup -*

# No DB cleanup
# Active-Active Infra to be set up
# UPS load test with  5x prod config

----

*Test monitoring -*

# New Relic monitoring to check TPS being hit
# Check the cpu and memory utilization. 
# MongoDB performance metrics

----

*Results reporting -*

# Observations and red flags"
Stress test with high TPS(5000) of /placeorderasync API,"*Background -*

* We are currently simulating 1000 TPS of placeorderAsync for UPS tests in 4 slots for 4 hours. We need to do a stress test at a total of 5000TPS with this API and check the stability of the system.

----

*Test-cases -*  

* Check stability at 2000TPS of placeorderAsync + 600TPS webhooks
* If the above works fine, check stability at 5000TPS of placeorderAsync + 600TPS webhooks
* Single-slot test - Identify bottlenecks

----

*Test setup -*

# No DB cleanup
# UPS load test JMX for 1st slot

----

*Test monitoring -*

# New Relic monitoring to check TPS being hit
# UPS Cloudwatch dashboard
# MongoDB performance metrics
# RDS metrics 

----

*Results reporting -* 

# Observations and red flags"
Stress test with high TPS of Roadie webhooks (Live + Order status),"*Background -*

* For UPS tests, we are currently simulating 600 TPS of order status update webhooks for 4 hours. We need to do a stress test at a total of 1000TPS. 500 TPS of order status update and 500 TPS of live webhooks. 

----

*Test-cases -*  

* Check stability at 1000TPS of webhooks alongside 1000TPS of placeorderAsync
* Single-slot test

----

*Test setup -*

# No DB cleanup
# Enable live webhooks from UPS load test JMX

----

*Test monitoring -*

# New Relic monitoring to check TPS being hit
# MongoDB performance metrics
# RDS metrics 

----

*Results reporting -* 

# Observations and red flags"
Auto-retry feature stress test ,After DL-2360 → Test case - Roadie crashes between a high TPS test (Check for fallback DSP)
300 RPS Roadie Integration Test,The task to track 300 RPS Integration tests with Roadie.
Performance Test for Introduce Bulk Cancel and Clone Feature with Updated Order Details (DL-15861),"*Overview:*

* Understand the Tech Solution and the Functional Requirements.
* Set up JMX to test the use case.
* Code review with respect to performance.
* Orders should be processed parallelly.
* Orders should be processed within 30 seconds.
* Our production infra should be able to handle the services without any performance degradation.
* The test should be conducted in such a way that at least 5 concurrent Bulk Cancel and Clone Order API calls are being made per second.

*Happy Flow:* All orders should be processed successfully with Self Delivery.

*Stress Testing:* API should not allow the processing of orders if more than 100 orders are sent. All orders should be processed successfully with a DSP Latency of 4 seconds using an estimate DSP."
Big Lots Test Prep [14th April & 19th April],"# To find Big Lots Test Setup [Rates full address [10 stores external id], SW full address  [10 stores external id], PO and DA-SB with showBoundaries]
# Verify it with bigs logs log for the above flavors
# Simulate Sandbox infra for PO, Rates, and SW
# Simulate Production Infra for DA-SB, remember to scale up ES on perf
# RDS to be used from the performance environment
# DA-SB is to be tested with 250 RPS
# Rest flavors need to be tested with 3 TPS
# Need to verify the scenarios for Biglots
# Move the latest Sandbox MongoDB snapshot to Perf
# Once done we will move DA Traffic to performance servers
## We must use the VPC link as we use NLBs in the performance environment.
## We will point to DA NLB via a VPC link
# Test DA-SB and DA-DSP
# Remove the rate limit before Roadie starts their tests.
# Need to revert changes once done.

DA-SB latency should be within 250 ms.

Need deployment plan when we move traffic. [~accountid:62b548d7f38b4dcf73dae06c] 

----

Scale RDS and check the effect on 200TPS load"
Performance Test of Cognida Integration <DL-14336>,"Performance test of the Cognida Integration:

* Check the performance of the following services.
** Rates
** DA-DSP
** DA-DSP show Estimates
** Get Estimates
* 
* Do a code review of the prediction engine library with respect to performance and highlight red flags if any.
* Do a code review of the prediction engine library integration in Rates, DA, and Estimates with respect to performance and highlight red flags if any.
* Monitor the Database during your tests and highlight red flags if any.
* Monitor the server metrics of the following during your tests and highlight red flags if any:
** Rates
** DA
** Prediction Provider [Cognida]
** Estimates
* Need final recommendations on the following if the existing setup is not efficient for our production use cases:
** Instance Type to be used for:
*** Rates
*** DA
*** Prediction Provider [Cognida]
*** Estimates
** Autoscaling Policies for:
*** Rates
*** DA
*** Prediction Provider [Cognida]
*** Estimates
** Alarms for the Autoscaling Policies for:
*** Rates
*** DA
*** Prediction Provider [Cognida]
*** Estimates
** Configuration for Capacity Provider for:
*** Rates
*** DA
*** Prediction Provider [Cognida]
*** Estimates
** Resources to be allocated to the following[task level or container level memory and cpu]:
*** Rates
*** DA
*** Prediction Provider [Cognida]
*** Estimates"
Belk shipping performance test,"Hi Sukumar and Sharmil,

Belk is asking for some specific load test data in order to decide whether to give us their shipping business.

We would like to show this info based on 40 TPS, 75 TPS, and 100 TPS (their max volume is around 90 TPS around Cyber Monday)

Here are the scenarios:

* Entire Place Order Process in under 5 seconds (Get Rates, Place Order, Send to Shipper, Label Creation, etc)
* Label Generation, download, send to printer process in the 2-3 second range
* Label generation and download to be sub 2 seconds
* Label Generation in less than 1 second"
Load test with Roadie for batch API,"We want to test the interaction between Roadie and DS. Check if we override provides estimates = false will work for roadie as Vulcan will not have Estimates call

1st Test- Low TPS, batchSequence, routeId, Webhooks

Consequent tests for Higher TPS"
Performance test for DL-13220 (Returns),Performance test for [https://delivery-solutions.atlassian.net/browse/DL-13220|https://delivery-solutions.atlassian.net/browse/DL-13220|smart-link]
Performance Evaluation of v2/filter request/response cleanup for rates service,
Script to get tcpdump from instance to local machine,"In order to analyze the traces on Wireshark, we need to get the tcpdump from the instance. This is the process - 

*How to get TCP dump for Wireshark analysis -* 

# Connect to ec2 using the session manager
# Install AWS CLI - 
{noformat}curl ""https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip"" -o ""awscliv2.zip""
yum install unzip
unzip awscliv2.zip
sudo ./aws/install{noformat}
# Add AmazonS3FullAccess policy to the IAM role of the instance
# Install tcpdump -
{noformat}yum install tcpdump{noformat}
# Run tcpdump command -
{noformat}tcpdump -i en0 -s 65535 -w <file_name>.pcap{noformat}
# Shift the file in the S3 bucket -
{noformat}/usr/local/bin/aws s3 cp <file_name>.pcap s3://<target_bucket_name>{noformat}



This process is completely manual right now. We need to create bash scripts to automate this."
Performance Evaluation Test for Reduce Event Loop Delay,
Add ability to restrict LMA Admins to specific businesses,"W2G is using 4 dsps - FedEx, USPS, UPS and DHL. They can create ZPL and PDF labels. We have to create a matrix at 200 RPS to understand the performance for the provider and label type combinations"
Multi-storeExternalId performance metrics,"Can you share the response time for the below, please note it's for the BL use case (BL staging configs applicable)



# rate call (with different store count), 
# DA -SB  (driving distance soln, random zips with different store count)
# SW (provider windows for PN)
# Create order (PN)"
Performance Test for DA Store Boundary Call,"* We have recently introduced ISOLine Boundaries for BigLots 
* It has more Points than the usual Boundaries. 
* We just want to ensure that it's not causing any degradation of the overall response. 
* Also get P95 & P99 for BL use case for DA 
* {noformat}curl --location --request POST 'https://sandbox.api.deliverysolutions.co/api/v2/deliveryAssurance' \
--header 'x-api-key: <API KEY BL>' \
--header 'tenantId: big_lots' \
--header 'cache-control: no-cache' \
--header 'content-type: application/json' \
--header 'request-id: 12345' \
--data-raw '{
    ""services"": [
        ""store-boundary""
    ],
    ""deliveryAddress"": {
        ""zipcode"": ""43228""
    },
    ""showBoundaries"":true,
    ""sortByDistance"" : true
     
}'{noformat}

"
Endurance Test - Oct -2022,
Migrate Sandbox Snapshot to Performance Cluster,Need a way to snapshot Sandbox Cluster and migrate the same to performance cluster
Performance Test of Provide Dynamic Windows Instead of Statically Defined Windows,
UPS Compliance Training - Optimisation - Nihal,
Clean up performance environment,
Need to setup a dashboard to view metrics at a glance of our performance services,"The performance dashboard should be a replica of the current production-performance-dashboard, [https://onenr.io/0MR2AY8eGwY|https://onenr.io/0MR2AY8eGwY].

It should cover at least the following services:

* Place Order
* Delivery Assurance
* Rates
* Smart Windows
* Edit Order
* Cancel Order
* Webhooks
* Notification
* DSP
* Overall Prod

And should cover at least the following metrics

* Tenant Wise RPM
* Tenant wise Max Response Times
* Tenant wise Average Response Times
* Tenant wise P95 Response Times
* Tenant wise P99 Response Times
* CPU Utilisation
* Memory Utilisation
* API Response Status RPM
* Throughput
* Request Count
* Tenant Wise Errors
* Errors"
Investigate why DA DSP caching performance degraded in 22.0.0,
Setup separate database for perform various test ,
Performance Benchmarking for Client Facing APIs (S2022-25.2.0 27-OCT-22),
Performance of all APIs (S2022-25.2.0 27-OCT-22),
Performance Benchmarking for Client Facing APIs (S2022-24.0.0 13-Sep-22),
Performance of all APIs (S2022-24.0.0 13-SEP-22),
Performance Benchmarking for client facing APIs (S2022-23.2.0 30-AUG-22),
Performance of all APIs (S2022-23.2.0 30-AUG-22),
Performance Benchmarking for client facing APIs (S2022-22.2.0 2-AUG-22),
Performance of all APIs (S2022-22.2.0 2-AUG-22),
Performance Test on Shopper & Runner implementation,
Performance test for the Order flow rewrite & locker facility,
Try increasing U Limit similar to API to check Rates Service performance for multiple store external ids,"It is observed that APIs are getting lagged due to network latency. Despite increase in number of containers, rates API performance did not improve for high number of store external ids. [~accountid:5f96548ac824730070ff11c2] suggested that this may be due to ULimit issues and number of async calls being made in the microservice. Hence, we need to explore this change and see what is the impact on rates service.

If it solves, then we also need to understand what ulimit should be set and what is the impact it has on performance"
Preparation for Big Lots Load Test,"*Details of Big Lots Load Test*

The idea is to do Website load test with 20K Vusers for 2 hours using Neoload.


Hi Zalak,

The load test is planned on 1/10 and 1/12 – 7 to 9 AM EST

 

|*Load Level*|*No of Vusers*|*Duration*|*Total Orders*|*DFS Orders*|
|1X ramp up|20 K|15 min| | |
|1X steady state|20 K|60 min|4500|225|
|Ramp Down| |10 min| | |
|*Total Duration*| |1 hour 25 min| | |

 

 

 

 

 

 

 

 "
Ability to launch and terminate a service's load balancer during performance tests,"Now that we have moved to NLB for all the services, we do not have a route 53 url for the services in the management account. The DNS resolution for the load balancers are done using the [deliverysolutions-internal.co|http://deliverysolutions-internal.co] domain. This is declared in the our route 53 hosted-zone in non-prod environment. Hence, instead of keeping load balancers alive throughout the month, we should keep them alive only during the tests.

In the performance admin backend, introduce ability to launch load balancer during a performance test, associate it with a target, change the route 53 value to this load balancer. Once, test is done, we should terminate the load balancer. We should save about $150+ per month



!Screenshot 2024-06-07 at 3.20.40 PM.png|width=751,height=223,alt=""Screenshot 2024-06-07 at 3.20.40 PM.png""!"
Performance Evaluation Test of <DL-4602>,
